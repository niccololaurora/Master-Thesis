\begin{figure}[h]
    \centering
    \includegraphics[scale=0.3]{sections/chapters/Chapter6/Images/Heatmaps/Local-Heatmaps/Heatmap-Digits-Small-Arch-L-train.pdf}
    \caption{This figure illustrates the \textbf{training} accuracy of \textit{small architectures} across different image sizes.}
    \label{fig:heatmap-Small-train}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.3]{sections/chapters/Chapter6/Images/Heatmaps/Local-Heatmaps/Heatmap-Digits-Small-Arch-L-val.pdf}
    \caption{This figure illustrates the \textbf{validation} accuracy of \textit{small architectures} across different image sizes.}
    \label{fig:heatmap-Small-val}
\end{figure}


In this section I want to compare \textit{small architectures} which have $< 3$ layers and $< 3$ qubits.
Figures \ref{fig:heatmap-Small-train} and \ref{fig:heatmap-Small-val} show the training and validation 
accuracy of \textit{small architectures} across different image sizes.
By looking at those figure we can make some observations:

\begin{itemize}
    \item \textbf{Training Accuracy}.\\
    We can state that the training accuracy is \textit{stable} across different image sizes.
    We expected that has the size of the images would increase we would get, but this is not the case.
    If we compare the two extreme cases which are $8\times8$ and $18\times18$ images we can see that 
    the latter case shows very similar accuracy values to the former and even better (1 qubit and 2 or 3 layers).
    
    \item \textbf{Validation Accuracy}.\\
    We can notice a very different behaviour for the validation accuracy.
    We can state that overfitting becomes more and more common as the images' size increases.
    For $8\times8$ images only thres architectures show overfitting (1-qubit 2 and 3 layers, 2-qubits 
    and 3 layers), whereas for $18\times18$ images every architecture except one (3-qubits and 1 layer) 
    shows overfitting.
\end{itemize}
